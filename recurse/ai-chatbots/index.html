<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Stanley Zheng"><meta name=description content="Programmer Blog, trying to share insights and knowledge picked up along the way."><meta name=generator content="Hugo 0.58.3"><title>RC 11: Stanleybot ðŸ¤– 1.Oh.n0 &middot; Stanley Zheng</title><link rel="shortcut icon" href=https://stanzheng.com/blog/images/favicon.ico><link rel=stylesheet href=https://stanzheng.com/blog/css/style.css><link rel=stylesheet href=https://stanzheng.com/blog/css/highlight.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.5.0/css/font-awesome.min.css><link href=https://stanzheng.com/blog/index.xml rel=alternate type=application/rss+xml title="Stanley Zheng"></head><body><nav class=main-nav><a href=https://stanzheng.com/blog/>Home</a>
<a href=https://stanzheng.com/>About</a>
<a class=cta href=https://tinyletter.com/stanzheng>Join My TinyLetter!</a></nav><section id=wrapper><article class=post><header><h1>RC 11: Stanleybot ðŸ¤– 1.Oh.n0</h1><h2 class=headline>February 15, 2017<br><a href=https://stanzheng.com/blog/tags/recurse>recurse</a></h2></header><section id=post-body><p>During my last week at Recurse, I wanted to apply the knowledge I&rsquo;ve gained about Machine Learning into a project. During my batch, I spent a portion of my time immersing myself with the terminology, concepts, and tooling but not as much as I hoped building and applying what I&rsquo;d learned.</p><p>On the final week, I wanted to attempt one of the projects on my back burner for a while. I had been thinking about the data that we generate every day on the multiple of services we utilize. Myself, I spend most of my time on data collection sources(noted <a href=https://blog.stanzheng.com/recurse/week-1/>here</a> and <a href=https://blog.stanzheng.com/recurse/halfway-checkin/>here</a>, chats, taking notes, and email. I was curious if given enough data about myself, would it be plausible to reproduce something that I could have written.</p><h1 id=collecting-the-data>Collecting the data</h1><p>The service I use the most if Facebook Messages and Messenger; I have been on the service for multiple year so surely I must have had thousands of conversations. I also a frequent participant in Slack.</p><ul><li>70K Facebook Messenger Archive messages <a href=https://github.com/cjroth/chronist/blob/master/lib/facebook.py>using Chris Roth&rsquo;s Chronist Scraper Methodology</a></li><li>10K Slack messages focused around conversations about tech and work.<br><br></li></ul><h1 id=lstm>LSTM</h1><p>Recurrent Neural networks using Long short term memory is better explained by these blogs and experts. In short using LSTM is a type of Recurrent Neural Network that is good at keeping context for generative models.</p><p>Given my conversations with friends and colleagues, it would give enough context to how I talk and speak hopefully. However, a key issue was that many of the taggings didn&rsquo;t have as because I would have to pull groups of messages and try and map it 1:1. It became a can of worms trying to rework the parsing to pull correct conversation pairs.</p><ul><li><a href=http://colah.github.io/posts/2015-08-Understanding-LSTMs/>http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li><li><a href=http://suriyadeepan.github.io/2016-06-28-easy-seq2seq/>http://suriyadeepan.github.io/2016-06-28-easy-seq2seq/</a></li><li><a href=http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/>http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/</a></li><li><a href="https://www.youtube.com/watch?v=SJDEOWLHYVo">https://www.youtube.com/watch?v=SJDEOWLHYVo</a></li></ul><h1 id=despair-and-rnns-on-zulip>Despair and RNNs on Zulip</h1><p>I was not excited the output I was getting from training the data and the incompleteness of the dataset. I remembered on Zulip someone was talking about a generative text bot mixed with Donald Trump&rsquo;s tweets and the first chapter 1984. To get halfway there with the data I had so far, I could feed it into a RNN to generate text.</p><ul><li><a href=http://karpathy.github.io/2015/05/21/rnn-effectiveness/>http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></li><li><a href=http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139>http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139</a></li></ul><p>Utilizing Yoav Goldberg&rsquo;s notebook I was able to feed it all 80K of lines of conversation I had generated in attempt to put out some plausible content. Reading it was like reading my diary, full of conversations that escaped my recent memory but still cringe worthy. (Maybe running it on private conversations isn&rsquo;t very wise&hellip;)</p><pre><code>Theres always next dominion
would look
All the poll, this your pitched sometime and stuff. She use to sit
my new year..
to see a doctor
Here is a time and login pages              canvas and repost
nothing has worked out of my idea)&quot;,
</code></pre><h2 id=conclusion>Conclusion</h2><p>I had fun time bootstrapping my knowledge about machine learning to create a plausible bot of myself. Going forward I&rsquo;d like to grab conversational pairs and mix my data with a helpbot to have a plausible closed domain bot that could pass. It was the first time I had a good intuition about a machine learning domain problem and how to get better results. I got to use Tensorflow, Jupyter Notebooks, Docker, and a whole load of python scripts to scrape my own data and dig through it. Eventually, it&rsquo;ll become a reality but I don&rsquo;t think anytime soon yet.</p></section></article><footer id=post-meta class=clearfix><a href=https://twitter.com/stanzheng><img class=avatar src="https://avatars0.githubusercontent.com/u/3683993?v=3&s=466"><div><span class=dark>Stanley Zheng</span>
<span>Polyglot who loves to experiment and explore</span>
<span><i class=rc-scout></i>Want to become a better programmer? <a href="https://www.recurse.com/scout/click?t=710ee58e0b0ad8d9f443f9c9440137f1">Join the Recurse Center!</a></span></div></a><section id=sharing><a class=twitter href="https://twitter.com/intent/tweet?text=https%3a%2f%2fstanzheng.com%2fblog%2frecurse%2fai-chatbots%2f - RC%2011%3a%20Stanleybot%20%f0%9f%a4%96%201.Oh.n0 by @stanzheng"><span class=icon-twitter>Tweet</span></a></section></footer><ul id=post-list class="archive readmore"><h3>Read more</h3><li><a href=https://stanzheng.com/blog/2018/>2018s<aside class=dates>Jul 28</aside></a></li><li><a href=https://stanzheng.com/blog/tags/certifications/>Certifications<aside class=dates>Jul 28</aside></a></li><li><a href=https://stanzheng.com/blog/tags/gcp/>GCP<aside class=dates>Jul 28</aside></a></li></ul><footer id=footer><div id=social><a class=symbol href=https://www.github.com/stanzheng><i class="fa fa-github"></i></a><a class=symbol href=https://www.instagram.com/yostanzheng><i class="fa fa-instagram"></i></a><a class=symbol href=/index.xml><i class="fa fa-rss"></i></a><a class=symbol href=https://www.twitter.com/stanzheng><i class="fa fa-twitter"></i></a></div><p class=small>Â© Copyright 2019 Stanley Zheng</p></footer></section><script src=//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js></script><script src=https://stanzheng.com/blog/js/main.js></script><script src=https://stanzheng.com/blog/js/highlight.js></script><script>hljs.initHighlightingOnLoad();</script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-73744856-3','auto');ga('send','pageview');}</script></body></html>